{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7bc9716-8930-4bf3-b280-e671bac9cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import scipy.special as special    \n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c0ebc8e-7dd9-4581-bef2-d49b9a26e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HMM (given)\n",
    "def make_hmm():\n",
    "     p = 1/200   # Mean seg length of 100. \n",
    "\n",
    "     t = np.array([[ 0.0, 1/2,   1/2 ],     # state 0 = start/end\n",
    "                   [ p, 1-2*p,     p ],     # state 1 = AluminumJesus\n",
    "                   [ p,     p, 1-2*p ]] )   # state 2 = T4\n",
    "\n",
    "     e = np.array([[   1/4,   1/4,   1/4,   1/4 ],    # unused; start/end state doesn't emit\n",
    "                   [ 0.166, 0.334, 0.334, 0.166 ],    # AluminumJesus residue composition\n",
    "                   [ 0.323, 0.177, 0.177, 0.323 ]] )  # T4 residue composition\n",
    "     return (t,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b480d300-5ce5-444a-b724-c07ef9d29766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our transition and emission matrices\n",
    "t, e = make_hmm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f372ef-b591-4139-a92e-0f4fe899edd4",
   "metadata": {},
   "source": [
    "# Question 1: Implement the (four) standard HMM algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7765eb-62fe-43a5-b6a1-ebe05b29ec21",
   "metadata": {},
   "source": [
    "Viterbi: find an optimal state path $\\pi$ (and its log probability log $P(x, \\pi∣\\theta)$), given the HMM parameters $\\theta$ and a sequence x. This function takes in a transmission and emission matrix, as well as a DNA sequence (one read)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e79403e-16b1-4082-8e79-7c4152e7a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for each nucleotide for ease of reference\n",
    "base_map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "\n",
    "reversed_base_map = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0547b50-80f1-4c61-9db6-e79b1fb75902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(t, e, sequence):\n",
    "    L = len(sequence)   \n",
    "    \n",
    "    # number of states (excluding start/end)\n",
    "    M = t.shape[0]-1\n",
    "    \n",
    "    # initialize V: an L x 2 matrix filled with negative infinity in order to store all of the calculated probabilities\n",
    "    V = np.full((M, L), -np.inf)    \n",
    "    \n",
    "    backtrack = np.zeros((M, L), dtype=int)  # Backpointer matrix\n",
    "    \n",
    "    # use the initial starting probabilities (from t) in order to initialize log-probabilities\n",
    "    for j in range(M):\n",
    "        V[j, 0] = np.log(t[0, j+1]) + np.log(e[j+1, base_map[sequence[0]]])\n",
    "    \n",
    "    # Recursion\n",
    "    # iterate through each position in a read/sequence\n",
    "    for i in range(1, L):  \n",
    "        base = sequence[i]\n",
    "        # iterate through every state\n",
    "        for k in range(M):  \n",
    "            # calculate probabilities for each transition and record the maximum in matrix V\n",
    "            max_prob, max_state = max(\n",
    "                (V[j, i-1] + np.log(t[j+1, k+1]) + np.log(e[k+1, base_map[base]]), \n",
    "                 j)\n",
    "                for j in range(M)\n",
    "            )\n",
    "            V[k, i] = max_prob\n",
    "            backtrack[k, i] = max_state\n",
    "\n",
    "    # termination step: compute final log-prob and determine last state for optimal path\n",
    "    last_probs = [(V[k, L-1] + np.log(t[k+1, 0]), k) for k in range(M)]\n",
    "    log_prob, last_state = max(last_probs)\n",
    "\n",
    "    # traceback to find the optimal path\n",
    "    paths = []\n",
    "    path = [last_state + 1]\n",
    "    for i in range(L - 1, 0, -1):\n",
    "        last_state = backtrack[last_state, i]\n",
    "        path.insert(0, last_state + 1)  \n",
    "\n",
    "    # return the optimal path and its log probability\n",
    "    return ''.join(map(str, path)), log_prob  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7afe8-b130-490e-8b0a-3b20d3643424",
   "metadata": {},
   "source": [
    "Forward: calculate the Forward dynamic programming matrix and the total log probability log $ P(x∣\\theta)$, given the HMM parameters $\\theta$ and a sequence $x$, and the total log probability log $P(x∣\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d85aaf-e82a-4944-aa4c-07924f7bcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(t, e, sequence):\n",
    "    L = len(sequence)  \n",
    "    M = t.shape[0]  \n",
    "\n",
    "    # initialization of forward dynamic programming matrix, initialized to -inf\n",
    "    F = np.full((M, L + 1), -np.inf)  \n",
    "    F[0, 0] = 0 \n",
    "\n",
    "    # using the starting probabilities, initialize the first column across all states\n",
    "    for k in range(1, M):\n",
    "        F[k, 1] = np.log(t[0, k]) + np.log(e[k, base_map[sequence[0]]])\n",
    "\n",
    "    # iterate over observed symbols, from 2 to L\n",
    "    for i in range(2, L + 1):  \n",
    "        # grab the previous base: str, from the sequence as we iterate\n",
    "        base = sequence[i-1]\n",
    "        \n",
    "        # iterate through every state, m (excluding start/end)\n",
    "        for k in range(1, M):  \n",
    "            # compute logsumexp over previous states j\n",
    "            log_probs = [F[j, i-1] + np.log(t[j, k]) + np.log(e[k, base_map[base]]) for j in range(1, M)]\n",
    "            F[k, i] = special.logsumexp(log_probs)\n",
    "\n",
    "    # termination step:\n",
    "    # calculate the total log probability by summing over transitions to the end state\n",
    "    log_prob_x = special.logsumexp([F[k, L] + np.log(t[k, 0]) for k in range(1, M)])\n",
    "\n",
    "    return F, log_prob_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4991d-cff6-4c19-ad4e-f1cc99e474cb",
   "metadata": {},
   "source": [
    "Backward: calculate the Backward dynamic programming matrix and the total log probability log $ P(x∣\\theta)$, given the HMM parameters $\\theta$ and a sequence $x$, and the total log probability log $P(x∣\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9955407f-2843-4631-aa45-88e528dc509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(t, e, sequence):\n",
    "    L = len(sequence)  \n",
    "    M = t.shape[0]  \n",
    "\n",
    "    # initialization of backward dynamic programming matrix, initialized to -inf\n",
    "    B = np.full((M, L+1), -np.inf)  \n",
    "\n",
    "    # using the starting probabilities, initialize the last column across all states\n",
    "    for k in range(1, M):  \n",
    "        # transition from state m to the end state (state 0)\n",
    "        B[k, L] = np.log(t[k, 0])  \n",
    "\n",
    "    # Recursion step:\n",
    "    # iterate backwards through the sequence to position 1\n",
    "    for i in range(L-1, 0, -1): \n",
    "        base = sequence[i]\n",
    "        for k in range(1, M):  # For each main state m\n",
    "            # Compute logsumexp over next states m_next\n",
    "            log_probs = [B[j, i + 1] + np.log(t[k, j]) + np.log(e[j, base_map[base]]) for j in range(1, M)]\n",
    "            B[k, i] = special.logsumexp(log_probs)\n",
    "\n",
    "    # Termination step:\n",
    "    # calculate the total log probability by summing over transitions from the start state (state 0) to each state j at the first position\n",
    "    log_prob_x = special.logsumexp([B[k, 1] + np.log(t[0, k]) + np.log(e[k, base_map[sequence[0]]]) for k in range(1, M)])\n",
    "\n",
    "    return B, log_prob_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1a159-5364-4044-8a27-642c07210e79",
   "metadata": {},
   "source": [
    "Decoding: given the Forward and Backward matrices, do posterior decoding to calculate $P(\\pi_i = k| x, \\theta)$, the probability that residue $i$ was generated by state $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db689535-c413-4185-a973-5cba71e6294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(F, f_prob_matrix, B, b_prob_matrix, threshold = 0.9):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - F: forward matrix\n",
    "    - f_prob: forward total log probability\n",
    "    - B: backward matrix \n",
    "    - b_prob: backward total log probability\n",
    "    \"\"\"\n",
    "\n",
    "    M, L = F.shape  # M is the number of states, L+1 includes the start state at position 0\n",
    "\n",
    "    # initialize the decoding matrix D to match the dimensions of the backward and forward algorithm total probability matrices\n",
    "    D = np.zeros((M, L))  \n",
    "    D[0, 0] = 1\n",
    "\n",
    "    # start in position 1 (or the second position) until the length of the sequence\n",
    "    for i in range(1, L):  \n",
    "        for k in range(1, M):  #For each main state m\n",
    "            D[k, i] = np.exp(F[k, i] + B[k, i] - f_prob_matrix)\n",
    "\n",
    "    # initialize decoded path\n",
    "    path = []\n",
    "\n",
    "    for i in range(1, L): \n",
    "        # find the state with the highest posterior probability\n",
    "        max_prob, max_state = max((D[1, i], 1), (D[2, i], 2))\n",
    "        \n",
    "        #check if the highest probability exceeds the threshold\n",
    "        if max_prob >= threshold:\n",
    "            path.append(str(max_state))\n",
    "        else:\n",
    "            # if the log probability is below the threshold, then we don't assume a state\n",
    "            path.append(\"U\")  \n",
    "    decoded_paths = \"\".join(str(state) for state in path)\n",
    "\n",
    "    # return a list of the decoded path as well as the posterior decoding matrix \n",
    "    return decoded_paths, D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cacbea1-e832-4af3-bf41-cc5710287be1",
   "metadata": {},
   "source": [
    "The accuracy of an inferred path is $\\frac{T}{T+F}$. Below, the <code>accuracy</code> calculates the accuracy of each algorithm for each of the 20 reads. It does this by taking in two arguments: a list of optimal paths from an HMM algorithm, and a list of reads that are the \"truth\" in order to check for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ff5d9c8-39d4-436a-8831-40ffc8dbc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(groundtruth_path, inferred_path):\n",
    "    T = 0 # true counts\n",
    "    F = 0 # false counts\n",
    "    for i in range(len(groundtruth_path)):\n",
    "        # disregard positions that are unknown ('U'), in the case we are comparing ground truths to paths inferred from \n",
    "        # the decoding algorithm\n",
    "        if inferred_path[i] == 'U':\n",
    "            continue\n",
    "        elif groundtruth_path[i] == inferred_path[i]:\n",
    "            T += 1\n",
    "        else:\n",
    "            F += 1\n",
    "\n",
    "    accuracy = T / (T+F)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446c8eb-b7c2-4a7e-88ea-1990725844b8",
   "metadata": {},
   "source": [
    "# Question 2: Do synthetic positive controls. Use the HMM to generate some synthetic positive control sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c00d1-220a-41ae-83da-ee6c5ccb252a",
   "metadata": {},
   "source": [
    "Below, my function <code>pos_controls</code> generates 'n' synthetic positive control sequences of length L using the transmission matrix t and emission matrix e. It also returns necessary information about these positive control sequences, such as the position where the sequence switches to another state as well as which state it was originally in. This will be useful for reconstructing the path later on, which we will need to test the accuracy of my Viterbi and decode algorithm. This is stored and outputted in a dataframe titled <code>sequence_info</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56896433-a785-42e6-a936-1e14e6714b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_controls(n, t, e):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - n: number of sequences to generate\n",
    "    - t: transition probability matrix\n",
    "    - e: emission probability matrix\n",
    "\n",
    "    \"\"\"\n",
    "    M = t.shape[0]\n",
    "    sequences_info = []\n",
    "\n",
    "    for i in range(n):\n",
    "        sequence = []\n",
    "        switch_positions = []\n",
    "        current_state = 0\n",
    "        start_state = None\n",
    "        end_state = None\n",
    "        position = 0\n",
    "\n",
    "        # allow the sequence to continue to generate until we return to the end state (state 0)\n",
    "        while True:\n",
    "            # transition to a new state based on the transition probabilities from current_state\n",
    "            next_state = np.random.choice(M, p=t[current_state])\n",
    "            \n",
    "            # if we've returned to state 0, we terminate the sequence\n",
    "            if next_state == 0:\n",
    "                # we record the end_state, or the second state of the sequence \n",
    "                end_state = current_state\n",
    "                break\n",
    "            \n",
    "            # record the first state after the start state as `start_state`\n",
    "            if start_state is None:\n",
    "                start_state = next_state\n",
    "            \n",
    "            # record the position where we transition to a new state\n",
    "            if current_state != next_state:\n",
    "                switch_positions.append(position)\n",
    "            \n",
    "            # produce a symbol based on the emission probabilities of the new state\n",
    "            symbol_index = np.random.choice(4, p=e[next_state])\n",
    "            symbol = reversed_base_map[symbol_index]\n",
    "            sequence.append(symbol)\n",
    "            \n",
    "            # Move to the next state\n",
    "            current_state = next_state\n",
    "            position += 1\n",
    "        \n",
    "        # convert the sequence list to a string\n",
    "        full_sequence = \"\".join(sequence)\n",
    "        \n",
    "        sequence_info = {\n",
    "            'sequence': full_sequence,\n",
    "            'switch_positions': switch_positions,\n",
    "            'start_state': start_state,\n",
    "            'end_state': end_state\n",
    "        }\n",
    "        # append the sequence information as a dictionary to the list 'sequences_info'\n",
    "        sequences_info.append(sequence_info)\n",
    "    \n",
    "    # convert sequences_info to a DataFrame\n",
    "    sequences_info_df = pd.DataFrame(sequences_info)\n",
    "\n",
    "    # return the dataframe to be used in calculating accuracies\n",
    "    return sequences_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aad566-484d-43bc-9440-fb51298f5c88",
   "metadata": {},
   "source": [
    "Below, I generate 10 synthetic sequences and display the positions at which they switched, as well as their start and end states, in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "013063be-9347-4fb2-8ca5-22a8e7d6adc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>switch_positions</th>\n",
       "      <th>start_state</th>\n",
       "      <th>end_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTACTTTACCTATTTAGATAAATAAACAAATTGAACGGCCCCGACG...</td>\n",
       "      <td>[0, 34]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGCCGATCGTTGTACCGCGCAAACGACGCCCAGGGGCTTGGGGGCG...</td>\n",
       "      <td>[0, 115, 156, 400]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTTGCCGGTGCACGGGGCACAGCTCTATAGAGGCATATTACATTTT...</td>\n",
       "      <td>[0, 13, 389, 555, 686, 755, 775, 1522, 1615]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAGGGGTCCGCGGTACGCGCCGAGTGGACCCATCAGTTGGCGCCCC...</td>\n",
       "      <td>[0, 98, 234]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGACAACATATGCACTACTCTAAGTAGAATGTTTACTTAGTTATAC...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCCGAGACCTCCGAGCGC</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTGCGGGAGGAGCTCAGTGGCGCCCGGACCCATCGCGGCCGAGTGG...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GAGTGGTTGATGCCATAATGAGAGTGTGCGCGACAATTGCGCCAGG...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TCGTTCTCATGAGTATATTTAGCATTATAATTCTATATTCGGGAAA...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CTTACGAGGCTATCCGCC</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  TTACTTTACCTATTTAGATAAATAAACAAATTGAACGGCCCCGACG...   \n",
       "1  AGCCGATCGTTGTACCGCGCAAACGACGCCCAGGGGCTTGGGGGCG...   \n",
       "2  CTTGCCGGTGCACGGGGCACAGCTCTATAGAGGCATATTACATTTT...   \n",
       "3  AAGGGGTCCGCGGTACGCGCCGAGTGGACCCATCAGTTGGCGCCCC...   \n",
       "4  TGACAACATATGCACTACTCTAAGTAGAATGTTTACTTAGTTATAC...   \n",
       "5                                 CCCGAGACCTCCGAGCGC   \n",
       "6  CTGCGGGAGGAGCTCAGTGGCGCCCGGACCCATCGCGGCCGAGTGG...   \n",
       "7  GAGTGGTTGATGCCATAATGAGAGTGTGCGCGACAATTGCGCCAGG...   \n",
       "8  TCGTTCTCATGAGTATATTTAGCATTATAATTCTATATTCGGGAAA...   \n",
       "9                                 CTTACGAGGCTATCCGCC   \n",
       "\n",
       "                               switch_positions  start_state  end_state  \n",
       "0                                       [0, 34]            2          1  \n",
       "1                            [0, 115, 156, 400]            1          2  \n",
       "2  [0, 13, 389, 555, 686, 755, 775, 1522, 1615]            1          1  \n",
       "3                                  [0, 98, 234]            1          1  \n",
       "4                                           [0]            2          2  \n",
       "5                                           [0]            1          1  \n",
       "6                                           [0]            1          1  \n",
       "7                                           [0]            1          1  \n",
       "8                                           [0]            2          2  \n",
       "9                                           [0]            1          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate 10 synthetic sequences\n",
    "n = 10\n",
    "\n",
    "syn_sequences_df = pos_controls(n, t, e)\n",
    "syn_sequences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2f435-c8c9-4196-997b-43a03aecbc96",
   "metadata": {},
   "source": [
    "Analyze the generated sequences (<code>syn_sequences</code>) with your HMM algorithms, obtaining a Viterbi state path and a decoded state path. Evaluate the accuracy of each path, for each generated sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74b24bf-8713-4053-a7d1-aed12ae0e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the viterbi and decoding algorithms on my synthetic sequences\n",
    "\n",
    "# set syn_sequences to the column of reads from syn_sequences_df\n",
    "syn_sequences= list(syn_sequences_df['sequence'])\n",
    "\n",
    "p_control_viterbi = []\n",
    "for sequence in syn_sequences:\n",
    "    path = viterbi(t, e, sequence)\n",
    "    p_control_viterbi.append(path[0])\n",
    "\n",
    "p_control_decoded = []\n",
    "for sequence in syn_sequences:\n",
    "    F, f_prob = forward(t, e, sequence)\n",
    "    B, b_prob = backward(t, e, sequence)\n",
    "    path = decode(F, f_prob, B, b_prob, threshold=0.9)[0]\n",
    "    p_control_decoded.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d78822-a22c-4680-8a44-2a6873ea5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the syn_sequences_df dataFrame into an array for ease of calculation \n",
    "truth_generated = np.array(syn_sequences_df)\n",
    "\n",
    "# parse the true paths (the true state switches) \n",
    "p_true_paths = []\n",
    "for i in range(truth_generated.shape[0]):\n",
    "    length=len(truth_generated[i,0])\n",
    "    if len(truth_generated[i, 1]) == 1:\n",
    "        path = str(truth_generated[i, 2]) * length\n",
    "    else:\n",
    "        path = str(truth_generated[i, 2]) * truth_generated[i, 1][1] + str(truth_generated[i, 3]) * (length - truth_generated[i, 1][1])\n",
    "    p_true_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a7d891-a65c-42c1-a835-e2d13aa12016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracies of the viterbi and decode algorithms\n",
    "p_viterbi_accuracies=[]\n",
    "\n",
    "for i in range(10):\n",
    "    p_viterbi_accuracies.append(accuracy(p_true_paths[i], p_control_viterbi[i]))\n",
    "\n",
    "p_decoded_accuracies=[]\n",
    "\n",
    "for i in range(10):\n",
    "    p_decoded_accuracies.append(accuracy(p_true_paths[i], p_control_decoded[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58817f70-a126-4727-98c5-f5fadd1441cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_#</th>\n",
       "      <th>p_controls_viterbi</th>\n",
       "      <th>p_controls_decoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611301</td>\n",
       "      <td>0.580460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.679675</td>\n",
       "      <td>0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.458955</td>\n",
       "      <td>0.533632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   read_#  p_controls_viterbi  p_controls_decoded\n",
       "0     0.0            0.980392            1.000000\n",
       "1     1.0            0.611301            0.580460\n",
       "2     2.0            0.679675            0.672727\n",
       "3     3.0            0.458955            0.533632\n",
       "4     4.0            1.000000            1.000000\n",
       "5     5.0            1.000000            1.000000\n",
       "6     6.0            1.000000            1.000000\n",
       "7     7.0            1.000000            1.000000\n",
       "8     8.0            1.000000            1.000000\n",
       "9     9.0            1.000000            1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe of accuracies\n",
    "p_accuracy_df = pd.DataFrame(columns=['read_#', 'p_controls_viterbi', 'p_controls_decoded'])\n",
    "p_accuracy_df['read_#'] = np.linspace(0,9, 10)\n",
    "p_accuracy_df['p_controls_viterbi'] = p_viterbi_accuracies\n",
    "p_accuracy_df['p_controls_decoded'] = p_decoded_accuracies\n",
    "p_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6217a3-9df9-467b-90a5-d54cd0f409c6",
   "metadata": {},
   "source": [
    "What trend(s) do you observe in these accuracies, with respect to features of the generated sequences?\n",
    "\n",
    "**Answer:** Most noticeably, the viterbi and decoded algorithms perfectly traceback the path for the generated sequences that had no state switches at all. The viterbi algorithm performed close to 100% or read 0, but performed extremely poorly for reads 1-3. This may be because read 0 only has one switch, while reads 1-3 include multiple switches. \n",
    "\n",
    "The decoded algorithm, on the other hand, performs well on ALL reads except for reads 1-3. Once again, perhaps this is due to the multiple state switches occuring in reads 1-3. The decoded algorithm performing better on read 0 also indicates that it perhaps performs better than the viterbi algorithm when there is a state switch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e5049-e9e7-4bcb-ad5f-75ded3462a5b",
   "metadata": {},
   "source": [
    "What do you observe about these generated sequences, compared to the actual features of Moriarty's reads? What are a couple of discrepancies where the HMM model is imperfectly describing what the actual data look like?\n",
    "\n",
    "**Answer:** These generated sequences are of varying lengths and can also undergo either no switches between states (genomes); the generated sequences can undergo multiple switches within one sequence, as shown with multiple values in the column 'switch_positions.' On the other hand, all of Moriarty's reads are of length 200 and undergo one state switch ONLY. They  start out in either AluminumJesus or T4, and switch to the other state once. \n",
    "\n",
    "The reason that our generated sequences fail to capture this is because of our HMM model's t matrix, which includes the probability that there is a state switch (regardless of whether or not one already occurred), which is 0.005. This indicates that a state switch can occur in any position. The probability of the sequence ending is also 0.005 at any position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43548727-71f5-4a1d-b16e-e38da1c8cf97",
   "metadata": {},
   "source": [
    "**Question 3:** Analyze Moriarty's read sequences.\n",
    "\n",
    "Use the HMM to analyze the 20 sequences in the file of Moriarty's reads. Here you'll need at least two additional functions: a function to parse the read sequences in the moriarty-reads.fa FASTA file, and a function to parse the ground truth table in 'moriarty-reads.truth' and convert those data for each read sequence into state paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09c2228d-0dd0-49a2-a2a3-e9bdbe73d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert FASTA file to a list of sequences\n",
    "def converter(file_name):\n",
    "\n",
    "    # read and open the file\n",
    "    with open(file_name, 'r') as file:\n",
    "        sequences = []\n",
    "        sequence = ''  \n",
    "\n",
    "        for line in file:\n",
    "            # if the line starts with '>', it's a new sequence header\n",
    "            if line.startswith('>'):\n",
    "                # if there's already a sequence, append it to sequences list\n",
    "                if sequence:\n",
    "                    sequences.append(sequence)\n",
    "                    sequence = ''  # reset for the next sequence\n",
    "\n",
    "            # strip whitespace/linebreaks and add the line to the current sequence\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "\n",
    "        # append the last sequence after the loop ends\n",
    "        if sequence:\n",
    "            sequences.append(sequence)\n",
    "    \n",
    "    # return the list of sequences\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cd1b93-b045-46ad-b94b-9137f48c2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the reads in 'moriarty-reads.fa'\n",
    "reads = converter('moriarty-reads.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "376e1b26-5a37-4744-87f1-b7299e94cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the viterbi algorithm on Moriarty's reads and store the optimal paths in viterbi_paths\n",
    "viterbi_paths = []\n",
    "for sequence in reads:\n",
    "    path = viterbi(t, e, sequence)\n",
    "    viterbi_paths.append(path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d894e5e4-9670-40ad-963e-7dc9169ab133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the decode algorithm on Moriarty's reads and store the optimal paths in decoded_paths\n",
    "decoded_paths = []\n",
    "for sequence in reads:\n",
    "    F, f_prob = forward(t, e, sequence)\n",
    "    B, b_prob = backward(t, e, sequence)\n",
    "    path = decode(F, f_prob, B, b_prob, threshold=0.9)[0]\n",
    "    decoded_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ce4975a-76f4-4e63-97a4-18f30cf83222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse the ground truth table so that we can compare the true paths with our inferred paths\n",
    "def read_truthfile(file_name):\n",
    "\n",
    "    with open(file_name, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        # initialize a matrix to store our switch position, start state, and end state \n",
    "        truth_matrix = np.zeros((len(lines) - 1, 3), dtype=int)\n",
    "        \n",
    "        # skip the header line, so start at line 1\n",
    "        for i, line in enumerate(lines[1:]):  \n",
    "            if line.startswith('read'):  \n",
    "                # split by '\\t', or tab\n",
    "                cols = line.strip().split('\\t')  \n",
    "                # Extract k, g0, g1 columns\n",
    "                k, g0, g1 = int(cols[2]), int(cols[3]), int(cols[4])\n",
    "                # append a new row for a new read\n",
    "                truth_matrix[i, :] = [k, g0, g1]  \n",
    "    \n",
    "    paths = []\n",
    "    for i in range(truth_matrix.shape[0]):\n",
    "        # create the paths based on g0, g1, and k\n",
    "        path = str(truth_matrix[i, 1]) * truth_matrix[i, 0] + str(truth_matrix[i, 2]) * (200 - truth_matrix[i, 0])\n",
    "        paths.append(path)\n",
    "    return truth_matrix, paths\n",
    "\n",
    "truth_file = \"moriarty-reads.truth\"\n",
    "truth_matrix, truth_paths = read_truthfile(truth_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc66ac3e-fab9-4c7d-b6e1-fe5105766819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracies for the paths produced using the viterbi and decode algorithm, respectively\n",
    "viterbi_accuracies=[]\n",
    "for i in range(20):\n",
    "    viterbi_accuracies.append(accuracy(truth_paths[i], viterbi_paths[i]))\n",
    "\n",
    "decoded_accuracies=[]\n",
    "for i in range(20):\n",
    "    decoded_accuracies.append(accuracy(truth_paths[i], decoded_paths[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b6ea5c7-e708-48f2-985d-47bd2318f37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_#</th>\n",
       "      <th>viterbi</th>\n",
       "      <th>decoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.970</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.970</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.983240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.994318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.978947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    read_#  viterbi   decoded\n",
       "0      0.0    0.995  1.000000\n",
       "1      1.0    0.970  1.000000\n",
       "2      2.0    0.980  1.000000\n",
       "3      3.0    1.000  1.000000\n",
       "4      4.0    0.995  1.000000\n",
       "5      5.0    0.995  1.000000\n",
       "6      6.0    0.990  1.000000\n",
       "7      7.0    0.970  1.000000\n",
       "8      8.0    0.900  0.917647\n",
       "9      9.0    0.995  1.000000\n",
       "10    10.0    0.995  1.000000\n",
       "11    11.0    0.970  1.000000\n",
       "12    12.0    0.935  0.983240\n",
       "13    13.0    0.875  0.994318\n",
       "14    14.0    0.995  1.000000\n",
       "15    15.0    1.000  1.000000\n",
       "16    16.0    0.960  0.978947\n",
       "17    17.0    0.990  1.000000\n",
       "18    18.0    0.980  1.000000\n",
       "19    19.0    1.000  1.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe of accuracies\n",
    "accuracy_df = pd.DataFrame(columns=['read_#', 'viterbi', 'decoded'])\n",
    "accuracy_df['read_#'] = np.linspace(0,19, 20)\n",
    "accuracy_df['viterbi'] = viterbi_accuracies\n",
    "accuracy_df['decoded'] = decoded_accuracies\n",
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587b0f4-8515-494b-bf42-890606de1940",
   "metadata": {},
   "source": [
    "Does the HMM accurately infer the structure of each chimeric read - which residues came from which source genome? How does posterior decoding compare to Viterbi for doing this inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b489a7-f448-4f29-9125-58bed4bfbfd4",
   "metadata": {},
   "source": [
    "**Answer:** The HMM more accurately infers the structure of each chimeric read when using the posterior decoding algorithm. The viterbi is slow to recognize quick switches. Thus, the accuracy dips when the switch point happens either very late or very early in the sequence. In the viterbi algorithm, the penalty of switching is higher than the gain you wuld get by switching. Therefore, the  forward/backward is better for cases in which there are quick switches.\n",
    "\n",
    "However, for some positions, we input a \"U\" in the inferred path of a sequence, as the decoding algorithm does not categorize  the state at that position (we don't always get an \"answer\" to compare to to the true paths). Therefore, we have less values to compare when using the decoding algorithm. The decoding algorithm thus performs worse in shorter sequences. \n",
    "\n",
    "Viterbi always gives us an \"answer\" in the sense that there is an inferred state at every position. Unlike the decoding algorithm, it does not check you how certain you are about a state, or it does not check for a most probable state assignment above a set threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5def83-f0c1-4eb6-896d-804de6207f76",
   "metadata": {},
   "source": [
    "# Question 4: Suggest a better HMM, and a better approach altogether"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e3443-f862-4f8b-b96f-ed7d32c02495",
   "metadata": {},
   "source": [
    "Two of the main issues identified with our HMM are that we do not produce sequences of a fixed length and there is also no limit to the number of state switches possible. This was evident in our synthetically generated positive controls, which were all of varying length and ranged in number of state switches, from no state switches to more than just one. This does not accurately capture the problem that is occuring in Moriarty's reads. Ideally, a reducible markov chain, which includes statess you cannot \"go out\" of, would be ideal; however, we still want to have the ability to start in either state. \n",
    "\n",
    "The first change would be to ensure that we run through 200 possible state changes, or include 200 positions in our path. This can be done by removing the probability that you could move from state 1 or 2 to state 0.\n",
    "\n",
    "In order to limit the number of state switches to 1, we could alter our model to include \"irreversible\" arrows. We would start in state 0 and have the option to move to state 1 or state 2. However, instead of connecting these two states with a transition probability of 0.005, we draw arrows from state 1 and state 2 to two newly labeled states, states 3 and 4, respectively. Although these states are labeled differently, only the labels are different -- state 3 will be the same in principle as state 2 and state 4 will be the same as state 1. In other words, states 1 and 4 could represent AluminumJesus and states 2 and 3 could represent T4. The transition and emission probabilities would be the same except the model can only move in two paths:\n",
    "1. from state 0 (start) -> state 1 (AlumnimumJesus) -> state 3 (T4)\n",
    "2. from state 0 (start) -> state 2 (T4) -> state 4 (AlumnimumJesus)\n",
    "\n",
    "The transition probability from one state to another will still be 0.005, but this model limits the number of state switches (after leaving state 0) to one switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbe91d92-e99a-41c1-b10a-1086fc58b399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.5\n",
      "IPython version      : 8.27.0\n",
      "\n",
      "jupyter   : 1.1.1\n",
      "numpy     : 2.1.1\n",
      "matplotlib: 3.9.2\n",
      "\n",
      "Compiler    : Clang 16.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 21.6.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p jupyter,numpy,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7a9e2-e6d6-408d-b041-195947e9d162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
